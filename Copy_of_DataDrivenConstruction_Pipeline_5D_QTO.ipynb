{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "021FgXtrp_JO"
      },
      "outputs": [],
      "source": [
        "###\n",
        "# Pipeline:  5D QTO\n",
        "# URI: https://DataDrivenConstruction.io/\n",
        "# Description: Grouping the model by parameters and filling the table to create 5D data\n",
        "# DataDrivenConstruction\n",
        "# This program is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "###\n",
        "\n",
        "import time, json, os, re, numpy as np, subprocess, warnings, pandas as pd\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import xml.etree.ElementTree as ET\n",
        "from slugify import slugify\n",
        "import requests\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Folders where the conversion files are located\n",
        "path = 'C:\\\\DataDrivenConstruction\\\\Input\\\\'\n",
        "outpath = path + 'Output\\\\'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2dK6aMdfBcf"
      },
      "outputs": [],
      "source": [
        "pathn = path + '/OpenCostEstimate'\n",
        "try:\n",
        "    os.mkdir(pathn)\n",
        "except:\n",
        "    pass\n",
        "# Properties for which we want to collect data on the amount of volume\n",
        "propstr =  ['Area', 'Volume', 'Width', 'Length', 'Perimeter', 'öööasdöööfake']\n",
        "search_parameters = ['Type Name', 'ObjectType', 'Reference', 'Familie und Typ', 'Familie']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtUmsK9Cyqh2",
        "outputId": "c64ac204-3194-48a5-9f60-6fbedbda5def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\DataDrivenConstruction\\Input\\Output\\Allplan-2008-Institute-Var-2-IFC.dae\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\Clinic_Architectural.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_Clinic_Architectural.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\Clinic_Electrical.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_Clinic_Electrical.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\Clinic_HVAC.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_Clinic_HVAC.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\Clinic_Structural.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_Clinic_Structural.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\Duplex_A_20110907.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_Duplex_A_20110907.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\Duplex_Electrical_20121207.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_Duplex_Electrical_20121207.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\Duplex_MEP_20110907.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_Duplex_MEP_20110907.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\Duplex_M_20111024_ROOMS_AND_SPACES.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_Duplex_M_20111024_ROOMS_AND_SPACES.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\Duplex_Plumbing_20121113.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_Duplex_Plumbing_20121113.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\House_Duplex_M.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_House_Duplex_M.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\IFC Schependomlaan.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_IFC Schependomlaan.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\OTC-Conference Center.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_OTC-Conference Center.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\rac_basic_sample_project.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_rac_basic_sample_project.json.csv.xlsx\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\rst_advanced_sample_project.dae\n",
            "C:\\DataDrivenConstruction\\Input\\Output\\Wellness center Sama.dae\n",
            "File created: C:\\DataDrivenConstruction\\Input\\/OpenCostEstimate/OCE_Wellness center Sama.json.csv.xlsx\n",
            "--- 1356.7674300670624 seconds ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'zip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Main function for grouping data and saving a file\n",
        "def crtable(filename):\n",
        "        filenamep = outpath + filename\n",
        "        df = pd.read_csv(filenamep, low_memory=False)\n",
        "        filedae = outpath + filename[:-8]+'dae'\n",
        "        print(filedae)\n",
        "        #    Fetching only numbers from string values of volumetric parameters\n",
        "        \n",
        "        propindf, sp = [], []   \n",
        "        \n",
        "        #grouping by element types for different formats\n",
        "        for el in search_parameters:\n",
        "            if el in df.columns:\n",
        "                sp.append(el)\n",
        "        search_parameter = sp[0]\n",
        "\n",
        "        # Converting all \"propstr\" values in columns to numeric values\n",
        "        for el in propstr:\n",
        "            if el in df.columns:\n",
        "                propindf.append(el)\n",
        "        def find_number(text):\n",
        "            num = re.findall(r'[0-9]+', text)\n",
        "            return \".\".join(num)\n",
        "        for el in propindf:\n",
        "            df[el] = df[el].astype(str)\n",
        "            df[el] = df[el].apply(lambda x: find_number(x))\n",
        "            df[el] = pd.to_numeric(df[el], errors='coerce')\n",
        "            df[el] = df[el].replace(np.nan, 0)\n",
        "            df[el] = df[el].replace('None', 0)\n",
        "            df[el] = df[el].fillna(0)\n",
        "        try:\n",
        "                df[el] = df[el].astype(float)\n",
        "        except:\n",
        "                pass\n",
        "\n",
        "        # Summation of all data that are grouped by search_parameter located in the propindf columns\n",
        "        df1=pd.pivot_table(df, index=[search_parameter],values=propindf,aggfunc=np.sum)\n",
        "        df1 = df1.add_prefix('Sum of ')\n",
        "\n",
        "        # Determination of the number of elements in groups\n",
        "        df2= df.groupby([search_parameter])[propindf[0]].agg(['count'])\n",
        "        dfallpar = pd.DataFrame()    \n",
        "        df['Unnamed: 0'] = df['Unnamed: 0'].astype(str)\n",
        "        comma = lambda x: ', '.join(x.unique())\n",
        "        df3 = df.groupby([search_parameter]) .agg({'Unnamed: 0': comma})\n",
        "        \n",
        "        # Collecting data into one dataframe\n",
        "        dfallpar = pd.concat([df2, df1, df3], axis=1)\n",
        "        dfallpar.rename(columns=({ 'Unnamed: 0': 'Id´s', 'count': 'Amount'}), inplace=True,)\n",
        "     \n",
        "        # Use and download a sample excel file\n",
        "        url = 'https://github.com/DataDrivenConstruction/Open-Estimation/raw/main/OpenEstimator.xlsx'\n",
        "        r = requests.get(url)\n",
        "        excelf = pathn + '/' + 'OCE_' + filename+'.xlsx'         \n",
        "        with open(excelf, 'wb') as f:\n",
        "                f.write(r.content)\n",
        "\n",
        "        # Saving data to file\n",
        "        book = load_workbook(excelf)\n",
        "        writer = pd.ExcelWriter(excelf, engine='openpyxl') \n",
        "        writer.book = book\n",
        "        writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
        "        dfallpar.to_excel(writer, 'BIM_Data')\n",
        "        writer.save()\n",
        "\n",
        "        dfallpar['type'] = dfallpar.index\n",
        "        dfallpar.insert(0, 'Group Key', dfallpar['type'].apply(slugify))\n",
        "        print(\"File created: \" + excelf)\n",
        "        \n",
        "        # Start sorting geometry from DAE file\n",
        "        # Formation of a data tree from the DAE format\n",
        "        daegrpath = pathn + '/' + 'DAEgroups_' + filename[:-9] \n",
        "        try:\n",
        "            os.mkdir(daegrpath)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # If the ID of an element from the group_ids_str list that was found earlier matches,\n",
        "        # all elements with this ID are found in the DAE file, and all other elements are deleted\n",
        "        filedaearr = []\n",
        "\n",
        "        for index, row in dfallpar.iterrows():\n",
        "            fileObject = open(filedae, \"r\")\n",
        "            treeq = ET.parse(fileObject)\n",
        "            root = treeq.getroot()\n",
        "            ET.register_namespace(\"\", \"http://www.collada.org/2005/11/COLLADASchema\")\n",
        "            geom_list = []\n",
        "            group_ids_str = []\n",
        "            group_ids_str = re.findall(r'\\d+', row['Id´s'])\n",
        "            for node in root.findall('.//{http://www.collada.org/2005/11/COLLADASchema}node'):\n",
        "                    tree = treeq\n",
        "                    if node.attrib['id'] in group_ids_str:\n",
        "                        try:\n",
        "                            url = list(node)[0].get('url')\n",
        "                            geom_list.append(url[1:])\n",
        "                        except:\n",
        "                            pass\n",
        "                    else:\n",
        "                            try:\n",
        "                                    nd = node.find(\n",
        "                                            '{http://www.collada.org/2005/11/COLLADASchema}instance_geometry')\n",
        "                                    node.remove(nd)\n",
        "                            except:\n",
        "                                    0\n",
        "            for geomet in root.findall('.//{http://www.collada.org/2005/11/COLLADASchema}geometry'):\n",
        "                        if geomet.attrib['id'] in geom_list:\n",
        "                                0\n",
        "                        else:\n",
        "                                try:\n",
        "                                    md = geomet.find(\n",
        "                                            '{http://www.collada.org/2005/11/COLLADASchema}mesh')\n",
        "                                    geomet.remove(md)\n",
        "                                except:\n",
        "                                    pass\n",
        "\n",
        "            # Formation of a new name for the DAE file with grouped elements\n",
        "            #words_pattern = '[a-zA-Z10-9]+'\n",
        "            invalid = '<>:\"/\\|?* '\n",
        "            for char in invalid:\n",
        "                index = index.replace(char, '')\n",
        "            regw = index + '.dae'\n",
        "            filedaena = daegrpath + '/' + regw\n",
        "            with open(filedaena, 'w') as f:\n",
        "                    tree.write(f, encoding='unicode')\n",
        "            #filedaearr.append(\"\"\"=HYPERLINK(\"[\"\"\"+\"/\" + \"DAEgroups_\" + filename[:-9] + \"/\" + regw + \"]\" + regw +\"\"\"\")\"\"\")\n",
        "            filedaearr.append('=HYPERLINK(LEFT(CELL(\"filename\",A1),FIND(\"[\",CELL(\"filename\",A1))-1)&\"' + \"DAEgroups_\" + filename[:-9] + '\\\\' + regw +'\",\"'+ regw + '\")')\n",
        "        dfallpar.drop(columns=['type'])\n",
        "        dfallpar.insert(7, \"Group geometry in DAE, file hyperlink *.dae\", filedaearr)\n",
        "        with open(excelf, 'wb') as f:\n",
        "                f.write(r.content)\n",
        "\n",
        "        # Saving data to file\n",
        "        book = load_workbook(excelf)\n",
        "        writer = pd.ExcelWriter(excelf, engine='openpyxl') \n",
        "        writer.book = book\n",
        "        writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
        "        dfallpar.to_excel(writer, 'BIM Data')\n",
        "        writer.save()\n",
        "\n",
        "# Function execution cycle for all CSV files in the folder\n",
        "for filename in os.listdir(outpath):\n",
        "    if filename.endswith(\"csv\"): \n",
        "        try:    \n",
        "            crtable(filename)\n",
        "        except:\n",
        "            pass\n",
        "            \n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "# Saving data to a ZIP file for downloading to a computer\n",
        "#!zip -r /content/file.zip /content/rvt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}